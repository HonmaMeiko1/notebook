## Hibench配置

github地址：[Intel-bigdata/HiBench: HiBench is a big data benchmark suite. (github.com)](https://github.com/Intel-bigdata/HiBench/tree/master)

1. 下载Hibench压缩包并在集群中进行解压

2. 在 ../HiBench-master下的pom.xml中修改版本信息

   ```xml
   <!--
   我仅将pom文件中的<scala version>标签的版本都修改成了2.11.12(原本是2.11.8)
   
   TODO 
   intel官方的7.1.1版本的Hibench的某些插件与maven3.9.9的最合适版本存在出入，
   但目前我没有发现明显的不兼容问题，留待后续出现不兼容问题时再进行修改
   -->
   ```

3. 在 ../HiBench-master下进行mvn编译，为集群准备mvn环境 (耗时较长，大约几个小时)

   ```sh
   # build all，也可以指定仅编译需要的部分——如spark hadoop scala等
   mvn -Dspark=2.4 -Dscala=2.11 clean package
   # 详情可见intel官方github ↑
   ```

4. 需要linux bc命令，用于生成Hibench日志报告

5. 在 ../HiBench-master/conf中修改hadoop.conf文件

   ```sh
   pwd ../HiBench-master
   cp conf/hadoop.conf.template conf/hadoop.conf
   vim conf/hadoop.conf
   ```

   ```
   <hadoop.conf>
   # Hadoop home
   hibench.hadoop.home     /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop
   
   # The path of hadoop executable
   hibench.hadoop.executable     ${hibench.hadoop.home}/bin/hadoop
               
   # Hadoop configraution directory
   hibench.hadoop.configure.dir  ${hibench.hadoop.home}/etc/hadoop
               
   # The root HDFS path to store HiBench data
   hibench.hdfs.master       hdfs://node01:8020/user/xiaoyouqi
                 
   # Hadoop release provider. Supported value: apache
   hibench.hadoop.release    cdh6.3.2 
   
   注意点：
   1. hibench.hadoop.home是本机上hadoop的安装路径
   2. hibench.hdfs.master中localhost是本机的IP，后面的端口号在vim /etc/hadoop/core-site.xml中可以查到：
       <?xml version="1.0" encoding="UTF-8"?>
           <!--Autogenerated by Cloudera Manager-->
           <configuration>
             <property>
               <name>fs.defaultFS</name>
               <value>hdfs://node01:8020</value>
             </property>
   即需要填写的端口号为8020
   ```

6. 在 ../HiBench-master/conf中修改hibench.conf文件

   ```
   #根据需求更改，例如wordcount，就在对应的/home/xiaoyouqi/HiBench-master/conf/workloads/micro/wordcount.conf中进行修改
   hibench.scale.profile                large
   
   # Mapper number in hadoop, partition number in Spark
   hibench.default.map.parallelism         8
   # Reducer nubmer in hadoop, shuffle partition number in Spark
   hibench.default.shuffle.parallelism     8
   ```

7. 在 ../HiBench-master/conf中修改spark.conf文件

   ```
   # Spark home
   hibench.spark.home      /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark
   ```

8. 在/home/xiaoyouqi/HiBench-master/bin/functions/load_config.py中可以看到

   ```py
   def probe_hadoop_examples_jars():
       # probe hadoop example jars
       if not HibenchConf.get("hibench.hadoop.examples.jar", ""):
           examples_jars_candidate_apache0 = HibenchConf[
               'hibench.hadoop.home'] + "/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar"
           examples_jars_candidate_list = [
               examples_jars_candidate_apache0
               ]
           HibenchConf["hibench.hadoop.examples.jar"] = exactly_one_file(
               examples_jars_candidate_list, "hibench.hadoop.examples.jar")
           HibenchConfRef["hibench.hadoop.examples.jar"] = "Inferred by " + \
               HibenchConf["hibench.hadoop.examples.jar"]
   
   def probe_hadoop_examples_test_jars():
       # probe hadoop examples test jars
       if not HibenchConf.get("hibench.hadoop.examples.test.jar", ""):
           examples_test_jars_candidate_apache0 = HibenchConf[
               'hibench.hadoop.home'] + "/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient*-tests.jar"
           examples_test_jars_candidate_list = [
               examples_test_jars_candidate_apache0
               ]
           HibenchConf["hibench.hadoop.examples.test.jar"] = exactly_one_file(
               examples_test_jars_candidate_list, "hibench.hadoop.examples.test.jar")
           HibenchConfRef["hibench.hadoop.examples.test.jar"] = "Inferred by " + \
               HibenchConf["hibench.hadoop.examples.test.jar"]
   ```

   即若不在../conf/hibench.conf下设置hibench.hadoop.examples.jar以及hibench.hadoop.examples.test.jar，配置文件就会去hadoop home中的share文件夹下寻找所需的jar包(原生hadoop中是有这个文件夹的，但实验室的没有)，故在hibench.conf下追加：

   ```
   # Hadoop jars setting
   hibench.hadoop.examples.jar        /home/xiaoyouqi/share/hadoop-mapreduce-examples-3.0.0.jar
   hibench.hadoop.examples.test.jar        /home/xiaoyouqi/share/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar
   ```

   其中这两个jar包是自己手动上传到上述路径中的。

9. 启动集群中的hdfs、yarn(实验室集群默认开启状态，无需手动启动)

10. #### 配置monitor.html

    需要在 ../Hibench/conf/hibench.conf文件下进行master、slaver的指定才能正常使用html可视化的形式监测作业运行过程中的信息

    ```
    hibench.masters.hostnames               node01
    hibench.slaves.hostnames                node01 node02 node03 node04 node05
    ```

### 配置ssh免密登录

- 在node01~node05这五台机器上需要配置过ssh免密登录才能实现hibench运行之后有monitor.html文件可视化监测作业执行过程的资源使用情况

  1. 创建密钥对

     ```sh
     # 一路回车，生成密钥对
     [xiaoyouqi@node01 ~]$ ssh-keygen -t rsa
     Generating public/private rsa key pair.
     Enter file in which to save the key (/home/xiaoyouqi/.ssh/id_rsa): 
     Enter passphrase (empty for no passphrase): 
     Enter same passphrase again: 
     Your identification has been saved in /home/xiaoyouqi/.ssh/id_rsa.
     Your public key has been saved in /home/xiaoyouqi/.ssh/id_rsa.pub.
     The key fingerprint is:
     SHA256:nFcA5VHo7POcHtGw0KnJTi79e0h/cxK6FezvqOlWAgM xiaoyouqi@node01
     The key's randomart image is:
     +---[RSA 2048]----+
     |        .o+o.    |
     |        E..+ .   |
     |         +o =    |
     |       . o== =   |
     |        S.*oo +  |
     |         *o ooo. |
     |        . +=.Bo. |
     |         . .B+++o|
     |           +O=.+=|
     +----[SHA256]-----+
     ```

  2. 查看密钥对

     ```shell
     [xiaoyouqi@node01 ~]$ ll .ssh
     总用量 12
     -rw------- 1 xiaoyouqi xiaoyouqi 1679 9月   3 17:49 id_rsa
     -rw-r--r-- 1 xiaoyouqi xiaoyouqi  398 9月   3 17:49 id_rsa.pub
     -rw-r--r-- 1 xiaoyouqi xiaoyouqi  181 9月   3 17:45 known_hosts
     ```

  3. copy公钥到各个节点，以本机为例，执行过程如下：

     ```sh
     [xiaoyouqi@node01 ~]$ ssh-copy-id node01
     /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/home/xiaoyouqi/.ssh/id_rsa.pub"
     The authenticity of host 'node01 (服务器ip)' can't be established.
     ECDSA key fingerprint is SHA256:......
     ECDSA key fingerprint is MD5:......
     Are you sure you want to continue connecting (yes/no)? yes
     /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
     /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
     xiaoyouqi@node01's password: 
     
     Number of key(s) added: 1
     Now try logging into the machine, with:   "ssh 'node01'"
     and check to make sure that only the key(s) you wanted were added.
     ```

  4. 在完成对其他几台机器的免密配置之后，验证免密登录

     ```sh
     [xiaoyouqi@node01 ~]$ ssh node02
     Last login: Tue Sep  3 18:20:11 2024 from node01
     ```

### HiBench目录说明

```
autogen：主要用于生成测试数据的源码目录
bin：测试脚本放置目录
common：公共依赖源码目录
conf：配置文件目录（Hibench/Hadoop/Spark等配置文件存放目录）
docker：docker 方式部署
flinkbench:Flink框架源码目录
gearpumpbench：gearpumpbench框架源码目录
hadoopbench：hadoop框架源码目录
sparkbench：spark框架的源码目录
stormbench：storm框架的源码目录
```

## Hibench使用例子——以hadoop集群上运行的wordcount为例

```sh
# 进行数据准备
cd ../Hibench-master
bin/workloads/micro/wordcount/prepare/prepare.sh
```

- 可在hdfs(node01:9870)中查看生成的数据：/user/xiaoyouqi/HiBench/Wordcount/Input

```sh
# 使用hadoop集群进行测试
cd ../Hibench-master
bin/workloads/micro/wordcount/hadoop/run.sh
```

- 可在hdfs(node01:9870)中查看运行的结果分区：/user/xiaoyouqi/HiBench/Wordcount/Output

- 在 ../HiBench-master/report/wordcount/hadoop中可以查看：

  | **../bench.log**           | **Raw logs on client side**                                  |
  | -------------------------- | ------------------------------------------------------------ |
  | **../monitor.html**        | **System utilization monitor results.**                      |
  | **../conf/wordcount.conf** | **Generated environment variable configurations for this workload.** |

  其中monitor.html可以下载到本地，然后在浏览器中打开，可以进行可视化监测作业运行过程中资源的使用情况。

